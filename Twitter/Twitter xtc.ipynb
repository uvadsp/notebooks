{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as requests\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import itertools\n",
    "import wget\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-27 10:54:09+00:00\n",
      "2022-07-01 00:13:38+00:00\n",
      "2022-03-20 09:12:33+00:00\n",
      "2021-12-15 14:45:59+00:00\n",
      "2021-09-20 18:15:05+00:00\n",
      "2021-06-28 15:54:32+00:00\n",
      "2021-02-24 18:01:05+00:00\n",
      "2020-11-18 16:51:00+00:00\n",
      "2020-07-13 06:02:22+00:00\n",
      "2020-03-08 17:37:58+00:00\n",
      "2020-01-06 15:45:09+00:00\n",
      "2019-10-09 13:08:33+00:00\n",
      "2019-08-20 05:07:38+00:00\n",
      "2019-07-02 05:21:15+00:00\n",
      "2019-04-08 18:01:52+00:00\n",
      "2019-02-03 14:12:31+00:00\n",
      "2018-12-18 16:43:07+00:00\n",
      "2018-12-17 06:47:04+00:00\n",
      "2018-10-22 13:39:07+00:00\n",
      "2018-08-27 08:15:16+00:00\n",
      "2018-05-11 12:22:05+00:00\n",
      "2017-12-02 11:50:38+00:00\n",
      "2017-06-25 14:12:56+00:00\n",
      "2017-03-03 19:12:41+00:00\n",
      "2016-10-21 08:26:18+00:00\n",
      "2016-07-03 23:07:15+00:00\n",
      "2016-04-21 10:14:00+00:00\n",
      "2016-01-03 13:07:06+00:00\n",
      "2015-10-09 20:44:34+00:00\n",
      "2015-07-21 08:40:42+00:00\n",
      "2015-05-28 15:52:01+00:00\n",
      "2015-03-13 15:25:11+00:00\n",
      "2015-01-23 19:05:55+00:00\n",
      "2014-12-18 09:49:06+00:00\n",
      "2014-10-22 11:49:20+00:00\n",
      "2014-09-05 09:16:20+00:00\n",
      "2014-06-03 11:14:36+00:00\n",
      "2014-04-01 17:49:51+00:00\n",
      "2014-01-19 19:27:45+00:00\n",
      "2013-12-03 08:30:33+00:00\n",
      "2013-10-26 04:38:20+00:00\n",
      "2013-09-08 21:02:25+00:00\n",
      "2013-08-09 14:36:50+00:00\n",
      "2013-06-14 20:42:44+00:00\n",
      "2013-05-28 21:03:30+00:00\n",
      "2013-04-16 11:13:08+00:00\n",
      "2013-03-06 18:51:00+00:00\n",
      "2013-01-25 21:58:01+00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Quotes</th>\n",
       "      <th>tweet.hashtags</th>\n",
       "      <th>sourceLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>22:51:19+00:00</td>\n",
       "      <td>VirtueelGedoe</td>\n",
       "      <td>@Politie Tijd om sommige drugs uit de illegali...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>21:03:24+00:00</td>\n",
       "      <td>ErikTiel</td>\n",
       "      <td>drug kopen in coffeeshops is geen probleem, xt...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>15:35:44+00:00</td>\n",
       "      <td>hesselink_ramon</td>\n",
       "      <td>Weet iemand trouwens dat het woord 'wappie' he...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>14:40:50+00:00</td>\n",
       "      <td>pzcredactie</td>\n",
       "      <td>Hennepkewekerij, speed en xtc aangetroffen in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Zapier.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>14:08:21+00:00</td>\n",
       "      <td>POL_Zeeland</td>\n",
       "      <td>In een woning aan de Kuipersdijk in #sHeerenho...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[sHeerenhoek]</td>\n",
       "      <td>OBI4wan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year        Date            Time             User  \\\n",
       "0  2022  2022-12-30  22:51:19+00:00    VirtueelGedoe   \n",
       "1  2022  2022-12-30  21:03:24+00:00         ErikTiel   \n",
       "2  2022  2022-12-30  15:35:44+00:00  hesselink_ramon   \n",
       "3  2022  2022-12-30  14:40:50+00:00      pzcredactie   \n",
       "4  2022  2022-12-30  14:08:21+00:00      POL_Zeeland   \n",
       "\n",
       "                                               Tweet  Replies  Retweets  \\\n",
       "0  @Politie Tijd om sommige drugs uit de illegali...        0         0   \n",
       "1  drug kopen in coffeeshops is geen probleem, xt...        1         1   \n",
       "2  Weet iemand trouwens dat het woord 'wappie' he...        8         8   \n",
       "3  Hennepkewekerij, speed en xtc aangetroffen in ...        0         0   \n",
       "4  In een woning aan de Kuipersdijk in #sHeerenho...        1         1   \n",
       "\n",
       "   Likes  Quotes tweet.hashtags          sourceLabel  \n",
       "0      0       0           None  Twitter for Android  \n",
       "1      2       0           None      Twitter Web App  \n",
       "2     44       0           None      Twitter Web App  \n",
       "3      0       0           None           Zapier.com  \n",
       "4      9       1  [sHeerenhoek]              OBI4wan  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrape twitter data\n",
    "query = 'xtc lang:nl until:2022-12-31 since:2013-01-01'\n",
    "tweets = []\n",
    "count = 0\n",
    "\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    count += 1\n",
    "    if(count == 1000):\n",
    "        count = 0\n",
    "        print(tweet.date)\n",
    "    \n",
    "    # Split the data and time for easier access later\n",
    "    datetime = str(tweet.date).split()\n",
    "    tweetdate = datetime[0]\n",
    "    tweetyear = tweetdate[:4]\n",
    "    tweettime = datetime[1]\n",
    "    tweets.append([tweetyear, tweetdate, tweettime, tweet.user.username, (tweet.content).replace('\\n', ' '), tweet.replyCount, tweet.retweetCount, tweet.likeCount, tweet.quoteCount, tweet.hashtags, tweet.sourceLabel]) \n",
    "\n",
    "# Select relevant data columns\n",
    "drugs_df = pd.DataFrame(tweets, columns=['Year', 'Date', 'Time', 'User', 'Tweet', 'Replies', 'Retweets', 'Likes', 'Quotes',  'tweet.hashtags', 'sourceLabel'])\n",
    "\n",
    "drugs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Quotes</th>\n",
       "      <th>tweet.hashtags</th>\n",
       "      <th>sourceLabel</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>22:51:19+00:00</td>\n",
       "      <td>VirtueelGedoe</td>\n",
       "      <td>@Politie Tijd om sommige drugs uit de illegali...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>21:03:24+00:00</td>\n",
       "      <td>ErikTiel</td>\n",
       "      <td>drug kopen in coffeeshops is geen probleem, xt...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year       Date            Time           User  \\\n",
       "0  2022 2022-12-30  22:51:19+00:00  VirtueelGedoe   \n",
       "1  2022 2022-12-30  21:03:24+00:00       ErikTiel   \n",
       "\n",
       "                                               Tweet  Replies  Retweets  \\\n",
       "0  @Politie Tijd om sommige drugs uit de illegali...        0         0   \n",
       "1  drug kopen in coffeeshops is geen probleem, xt...        1         1   \n",
       "\n",
       "   Likes  Quotes tweet.hashtags          sourceLabel  week  \n",
       "0      0       0           None  Twitter for Android    52  \n",
       "1      2       0           None      Twitter Web App    52  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add week to data\n",
    "drugs_df['Date'] = pd.to_datetime(drugs_df['Date'], errors='coerce')\n",
    "drugs_df['week'] = drugs_df.Date.apply(lambda x: x.strftime('%U')).astype(int)\n",
    "\n",
    "drugs_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "drugs_df.to_csv(\"datasets/tweets_corpus_xtc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset for dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year  week\n",
       "2013  0       149\n",
       "      1       287\n",
       "      2       203\n",
       "      3       158\n",
       "      4       163\n",
       "             ... \n",
       "2022  48       84\n",
       "      49       48\n",
       "      50       68\n",
       "      51       55\n",
       "      52       51\n",
       "Name: Tweet, Length: 530, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# absolute values\n",
    "absolute = drugs_df.groupby(['Year', 'week'])['Tweet'].count()\n",
    "absolute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute.to_csv(\"datasets/absolute_tweet_values_xtc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply grouping\n",
    "average_per_year = drugs_df.groupby(['Year'])['week'].count() / 52\n",
    "tweets_per_week = drugs_df.groupby(['Year', 'week'])['Tweet'].count()\n",
    "max_tweets_per_year = tweets_per_week.groupby(level=0).apply(max)\n",
    "min_tweets_per_year = tweets_per_week.groupby(level=0).apply(min)\n",
    "\n",
    "# make relative\n",
    "relative_tweets_per_week = tweets_per_week / average_per_year\n",
    "max_relative_tweets_per_year = relative_tweets_per_week.groupby(level=0).apply(max)\n",
    "\n",
    "# normalize\n",
    "relative = relative_tweets_per_week / max_relative_tweets_per_year * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative.to_csv(\"datasets/relative_tweet_values_xtc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function aims to split all the text into tokens\n",
    "def split_words_inclusive(text):\n",
    "    if(type(text) != str):\n",
    "        return []\n",
    "    \n",
    "    # fetch alphabetic characters\n",
    "    text = re.sub(\"[^a-zA-Z@#]\", \" \", text)\n",
    "\n",
    "    # convert text to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # split text into tokens to remove whitespaces\n",
    "    tokens = text.split()\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# This function uses a Gensim function to remove stopwords \n",
    "# and eliminates some words which have no meaning based on manual inspection\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def remove_stopwords(text):\n",
    "    tokens = split_words_inclusive(text)\n",
    "    text = \" \".join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    text = remove_stopwords(text)\n",
    "    \n",
    "    # Words specifically removed because of manual inspection\n",
    "    text = text.replace(\" amp \", \"\")\n",
    "    text = text.replace(\" t \", \"\")\n",
    "    text = text.replace(\" s \", \"\")\n",
    "    text = text.replace(\" http \", \"\")\n",
    "    text = text.replace(\" m \", \"\")\n",
    "    \n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "#This function splits the text into tokens and lammatizes it so it is suited for the Roberta model\n",
    "def pre_process(text):\n",
    "    if(type(text) != str):\n",
    "        return \"\"\n",
    "    \n",
    "    # fetch alphabetic characters\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "\n",
    "    # convert text to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # split text into tokens to remove whitespaces\n",
    "    tokens = text.split()\n",
    "\n",
    "    return \" \".join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "\n",
    "# This function determines whether the word cocaine is contained in a tweet.\n",
    "\n",
    "def filter_drug(text):\n",
    "    if(type(text) != str):\n",
    "        return 0\n",
    "    \n",
    "    # fetch text  including tesla\n",
    "    if \"cocaine\" in text or \"cocaine\" in text:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function to clean data\n",
    "# df_cocaine_clean = df_cocaine.copy()\n",
    "# df_cocaine_clean['Tweet'] = df_cocaine['content'].apply(split_words_inclusive)\n",
    "# df_cocaine_clean['Tweet no stopwords'] = df_cocaine_clean['Tweet'].apply(remove_stopwords)\n",
    "# df_cocaine_clean['Clean tweet'] = df_cocaine_clean['content'].apply(pre_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
